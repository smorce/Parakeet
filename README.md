https://github.com/smorce/Parakeet



後で消す：
エラーの原因は、Gradioのバージョンアップに伴い、gr.Audioの仕様が変更されたことでした。source引数がsources（複数形）になり、リスト形式（["microphone"]）で指定する必要がありました。



## 使い方

### 効率的な起動方法（推奨）

開発時は以下の効率的な起動方法を使用してください：

1. **高速起動（推奨）** - 既存のコンテナを再利用
```bash
./dev.sh
```

2. **通常起動** - キャッシュを活用したビルド
```bash
./start.sh
```

3. **クリーンビルド** - 全て再ビルド（依存関係を変更した場合）
```bash
./start.sh --clean
```

4. **依存関係チェック** - どの起動方法が適切かを提案
```bash
./check-deps.sh
```

### 起動モードの使い分け

- **初回起動時**: `./start.sh` で通常ビルド
- **日常の開発**: `./dev.sh` で高速起動（数秒で起動）
- **requirements.txt変更後**: `./start.sh --clean` でクリーンビルド
- **迷った時**: `./check-deps.sh` で適切なモードを確認

終了したあとは
```bash
docker compose down
```


# リアルタイム文字起こしアプリケーション

## 概要

このプロジェクトは、マイクからの音声入力をリアルタイムで文字起こしし、Webインターフェースに表示するアプリケーションです。Dockerを使用して環境を構築し、NVIDIA NeMoのASRモデル、Silero VADによる音声区間検出、GradioによるUIを組み合わせています。

## 音声文字起こし方式の比較

本システムでは、2つの異なる音声文字起こし方式を提供しています：

### 🎯 処理方式の概要

| 項目 | ファイル処理 | マイク処理 | リアルタイム処理 |
|------|-------------|------------|----------------|
| **エンジン** | NVIDIA Parakeet-TDT-CTC | Google Web Speech API | Google Web Speech API + VAD |
| **動作場所** | ローカル（GPU/CPU） | クラウド | クラウド |
| **モデル読み込み** | 必要（重い処理） | 不要 | 不要 |
| **メモリ使用** | 大量（GPU/CPUメモリ） | 最小限 | 最小限 |
| **長時間音声** | 分割処理対応（30秒単位） | 短時間推奨 | 連続処理対応 |
| **オフライン** | 可能 | 不可（インターネット必須） | 不可（インターネット必須） |
| **処理速度** | デバイス依存 | ネットワーク依存 | リアルタイム |
| **プライバシー** | 完全ローカル | 音声がGoogleに送信 | 音声がGoogleに送信 |
| **操作方法** | ファイルアップロード | 手動録音 | 自動音声検出 |

### 📁 ファイルアップロード処理

**特徴:**
- NVIDIA Parakeet-TDT-CTCモデルを使用したローカル処理
- GPU/CPU自動判定とフォールバック機能
- 長時間音声ファイルの自動分割処理（30秒単位）
- メモリ効率的な処理とエラー回復機能

**対応フォーマット:** WAV, MP3, FLAC, M4A など

**メリット:**
- 完全オフライン動作
- プライバシー保護（音声データが外部に送信されない）
- 長時間音声ファイルの処理に対応
- 高品質な日本語音声認識

**デメリット:**
- 初回モデル読み込みに時間がかかる
- GPU/CPUリソースを大量消費
- メモリ不足時の処理が複雑

### 🎙️ マイク録音処理

**特徴:**
- Google Web Speech APIを使用したクラウド処理
- 軽量で高速起動
- リアルタイム音声認識に最適化

**メリット:**
- 軽量で高速起動
- モデル読み込み不要
- GPU/CPUリソース消費なし
- Googleの高品質音声認識

**デメリット:**
- インターネット接続が必須
- 長時間音声の制限
- プライバシー上の懸念（音声がGoogleに送信）
- APIの利用制限やコスト

### ⚡ リアルタイム文字起こし処理（ブラウザネイティブ）

**特徴:**
- ブラウザネイティブ Web Speech API による音声検出
- MediaRecorder による高品質音声録音
- Google Cloud Speech API による高精度文字起こし
- タイムスタンプ付きリアルタイム結果表示
- ハンズフリー操作（音声検出による自動処理）

**技術詳細:**
- Web Speech API の `onaudiostart` イベントによる音声検出
- 音声検出時に MediaRecorder で自動録音開始
- `onsoundend` イベントで自動録音停止・文字起こし実行
- ブラウザ内で完結する高速処理（サーバー往復なし）

**メリット:**
- 🚀 ブラウザネイティブによる高速処理
- 🎤 ハンズフリー操作（ボタン操作不要）
- ⚡ 低遅延のリアルタイム認識
- 🔄 連続的な音声認識
- 🎯 高精度な音声検出
- 💾 結果の自動保存・ダウンロード機能

**デメリット:**
- 🌐 インターネット接続が必須
- 🔒 音声データがGoogleに送信される
- 🌍 ブラウザ対応状況に依存
- 🔑 Google Cloud Speech API キーが必要（高精度版）

### 🚀 使い分けの指針

**ファイル処理を選ぶべき場面:**
- 長時間の音声ファイルを処理したい
- オフライン環境で動作させたい
- プライバシーを重視する
- 高品質な文字起こしが必要

**マイク処理を選ぶべき場面:**
- 短時間の音声を素早く文字起こししたい
- システムリソースを節約したい
- インターネット接続が安定している
- 簡単な音声メモの文字起こし

**リアルタイム処理を選ぶべき場面:**
- 会議や講演のリアルタイム文字起こし
- ハンズフリーでの音声入力が必要
- 連続的な音声認識を行いたい
- インタラクティブな音声アプリケーション

## 主な特徴

- **リアルタイム文字起こし:** マイクからの音声を低遅延でテキストに変換します。
- **音声区間検出 (VAD):** Silero VADを用いて無音区間を除外し、効率的に発話のみを処理します。
- **Webインターフェース:** Gradioを利用したシンプルで直感的なUIを提供します。タブ切り替えで2つの文字起こし方式を簡単に選択できます。
- **デュアル処理方式:** ローカル処理（ファイル）とクラウド処理（マイク）の2つの方式を用途に応じて使い分け可能です。
- **コンテナ化:** DockerとDocker Composeにより、依存関係を含めた実行環境を簡単に構築・再現できます。
- **GPU対応:** NVIDIA GPUを自動で検出し、高速な文字起こし処理を実現します。GPUが利用できない場合はCPUにフォールバックします。

## API

http://localhost:5466/docs

Gradio の APIサーバーはどうやってもうまく使えないので、FastAPIサーバーを実装した。

## アーキテクチャ

本システムは、以下のコンポーネントがマルチスレッドで並列動作することで実現されています。

- **Gradio UI (メインスレッド):** ユーザー操作の受付と結果のストリーミング表示を担当します。
- **音声入力スレッド:** `sounddevice` を用いてマイクから音声を取得します。
- **VAD処理スレッド:** `silero-vad` を用いて音声区間を検出します。
- **文字起こしスレッド:** NVIDIA NeMo ASRモデル (`nvidia/parakeet-tdt_ctc-0.6b-ja`) で文字起こしを実行します。

```mermaid
graph TD
    subgraph "Gradio App (Main Thread)"
        A[Gradio UI <br> (Web Interface)] -- ボタン操作 --> B{録音状態フラグ};
        A -- "yield"による更新 --> C[出力用テキストボックス];
        D[結果キュー<br>(queue.Queue)] -- UI更新ループが読み出し --> A;
    end

    subgraph "ワーカースレッド1: 音声入力"
        E[マイク<br>(sounddevice)] -- 音声チャンク --> F[音声キュー<br>(queue.Queue)];
    end
    B -- 状態を監視 --> E;

    subgraph "ワーカースレッド2: VAD"
        G[VAD処理<br>(silero-vad)] -- get --> F;
        G -- 発話音声 --> H[文字起こしキュー<br>(queue.Queue)];
    end

    subgraph "ワーカースレッド3: 文字起こし"
        I[Nemo ASRモデル<br>(Parakeet)] -- get --> H;
        I -- テキスト --> D;
    end
```

## 実行方法

### 前提条件

- [Docker](https://www.docker.com/get-started)
- [Docker Compose](https://docs.docker.com/compose/install/) (Docker Desktopには通常含まれています)
- ホストマシンに接続されたマイク

### 手順

1.  このリポジトリをクローンまたはダウンロードします。

2.  ターミナルでプロジェクトのルートディレクトリに移動します。

3.  以下のコマンドを実行して、Dockerイメージをビルドし、コンテナを起動します。
    ```bash
    docker compose up --build
    ```
    初回起動時はモデルのダウンロードなどにより時間がかかる場合があります。

4.  ビルドと起動が完了したら、Webブラウザで以下のURLにアクセスします。
    [http://localhost:3791](http://localhost:3791)

5.  表示されたGradioのインターフェースで以下の2つの方式から選択できます：
    
    **⬆️ ファイルから文字起こし（推奨）:**
    - 音声ファイルをアップロードして高品質な文字起こしを実行
    - 長時間音声対応、完全オフライン処理
    
    **🎙️ マイクから文字起こし:**
- ブラウザでマイク録音し、Google APIで素早く文字起こし
- 短時間音声向け、インターネット接続必須

**⚡ リアルタイム文字起こし:**
- 音声検出による自動録音・文字起こし機能
- VAD（音声活動検出）によるリアルタイム処理
- 話しかけるだけで自動的に文字起こし開始

## ファイル構成

-   `Dockerfile`: アプリケーションの実行環境を定義します。CUDA、Python、必要なシステムライブラリ（`portaudio19-dev`など）をインストールします。
-   `compose.yaml`: Docker Composeの設定ファイルです。サービスのビルド方法、ポートマッピング(`3791:3791`)、マイクデバイスのマウントなどを定義します。
-   `requirements.txt`: Pythonの依存ライブラリをリストします。
-   `scripts/realtime_transcribe_gradio.py`: アプリケーションの本体です。Gradio UI、音声処理、文字起こしのロジックが実装されています。

## カスタマイズ

### VAD感度の調整

音声検出の感度は、環境ノイズや話者の声量に合わせて調整できます。
`scripts/realtime_transcribe_gradio.py` 内の以下の行の `threshold` 値を変更してください。

```python
# scripts/realtime_transcribe_gradio.py

# ...
vad_iterator = VADIterator(vad_model, threshold=0.7) # この値を調整 (0.0 ~ 1.0)
# ...
```

-   `threshold` を高くすると、より大きな音でないと発話として認識されにくくなります（ノイズが多い環境向け）。
-   `threshold` を低くすると、小さな音でも発話として認識されやすくなります（静かな環境向け）。
