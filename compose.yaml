services:
  realtime-speech-to-text:
    build: .
    image: realtime-speech-to-text:latest
    container_name: realtime-speech-to-text-container
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=all
      # GPU メモリ分割を有効化
      - CUDA_MPS_ENABLE_PER_CTX_DEVICE_MULTIPROCESSOR_PARTITIONING=1
      # PyTorchのメモリ効率化
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
      # Hugging Face Hubキャッシュの設定
      - HF_HOME=/app/.cache/huggingface
      # HTTP タイムアウトの設定
      - HF_HUB_DOWNLOAD_TIMEOUT=300
    ports:
      - "3791:3791"
      - "5466:5466"
    volumes:
      # Hugging Face モデルキャッシュの永続化
      - hf_cache:/app/.cache/huggingface
    command: ["sh", "-c", "python3 fastapi_server.py & python3 scripts/gradio_transcribe.py"]
    shm_size: '4.0gb'
    tty: true
    restart: "no"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  hf_cache:
    driver: local